<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Thomas EnXu Li</title>

  <meta name="author" content="Thomas EnXu Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Thomas EnXu Li</name>
              </p>
              <p>I am a fourth year <a href="https://engsci.utoronto.ca/program/what-is-engsci/">Engineering Science</a> student at the University of Toronto, majoring in <strong>Robotics Engineering</strong> and minoring in <strong>Artificial Intelligence</strong> and <strong>Business</strong> . I'm in the process of completing my Professional Experience Year (PEY) as a <strong>research intern</strong> at <a href="http://www.noahlab.com.hk/#/home">Huawei Noah's Ark Research Lab</a>, where I work on <strong>LiDAR semantic segmentation and panoptic segmentation systems for self-driving vehicles</strong>. This September, I will be joining <a href="https://www.trailab.utias.utoronto.ca">The Toronto Robotics and AI Laboratory (TRAIL)</a> to work on my bachelors thesis with the guidance of <a href="https://www.trailab.utias.utoronto.ca/stevenwaslander">Prof. Steven Waslander</a>.
              </p>
              <p>
                What I value the most is creativity and productivity.
              </p>
              <p style="text-align:center">
                <a href="mailto:thomasenxu.li@mail.utoronto.ca">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.ca/citations?user=Bk4LuGYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/thomas-enxuli/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/thomas-enxu-li/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/thomas.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/thomas.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


<!-- education -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color: #f9f9f9;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/uoft.png" alt="clean-usnob" width="140" height="140">
            </td>
            <td width="75%" valign="middle">
              <papertitle>B.A.Sc in Engineering Science, Robotics (in progress)</papertitle>
              <br>
                Faculty of Applied Science and Engineering, University of Toronto
              <br>
                Sep 2017 - Apr 2022 | Toronto, ON
              <p> </p>
              <em><strong>3rd Year Annual GPA: 3.97</strong></em>
              <br>
              <em><strong>Daisy Intelligence Scholarship</strong>, 2020</em>
              <br>
              <em><strong>NSERC Undergraduate Research Award</strong>, 2019</em>
              <br>
              <em><strong>U of T Scholar</strong>, 2017</em>
              <br>
              <em><strong>Dean's Honour List - 2017-2021</strong></em>
            </td>
          </tr>
        </tbody></table>


<!-- research, publications -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, and robotics. Much of my research is about 3D perception with LiDAR point clouds.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/gps3.gif" alt="clean-usnob" width="180" height="140">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>GP-S3Net: Graph-based Panoptic Sparse Semantic Segmentation Network</papertitle>
              <br>
              Ryan Razani*,
							<a href="https://rancheng.github.io/about/">Ran Cheng</a>*,
              <strong>Enxu Li</strong>,
							Ehsan Taghavi,
              Yuan Ren,
							Bingbing Liu
              <br>
              manuscript submitted to <em>ICCV</em>, 2021
              <br>
              <p>We present a novel panoptic segmentation network using <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_AF2-S3Net_Attentive_Feature_Fusion_With_Adaptive_Feature_Selection_for_Sparse_CVPR_2021_paper.pdf">(AF)2-S3Net</a> as the semantic backbone and a GCNN to segment foreground points into instances. This approach outperforms the current state-of-the-art approaches, by a significant margin across public available datasets such as, nuScenes and SemanticPOSS, ranking 1st on the competitive public <a href="https://competitions.codalab.org/competitions/24025#results">SemanticKITTI</a> leaderboard competition upon publication.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/af2s3.gif" alt="clean-usnob" width="180" height="140">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_AF2-S3Net_Attentive_Feature_Fusion_With_Adaptive_Feature_Selection_for_Sparse_CVPR_2021_paper.pdf">
                <papertitle>(AF)2-S3Net: Attentive Feature Fusion with Adaptive Feature Selection for Sparse Semantic Segmentation Network</papertitle>
              </a>
              <br>
							<a href="https://rancheng.github.io/about/">Ran Cheng</a>,
							Ryan Razani,
							Ehsan Taghavi,
              <strong>Enxu Li</strong>,
							Bingbing Liu
              <br>
              <em>CVPR</em>, 2021
              <br>
              <p>We present a novel multi- branch attentive feature fusion module in the encoder and a unique adaptive feature selection module with feature map re-weighting in the decoder. This method ranks 1st on both <a href="https://www.nuscenes.org/lidar-segmentation?externalData=all&mapData=all&modalities=Any">nuScenes-lidarseg</a> and <a href="https://competitions.codalab.org/competitions/20331#results">SemanticKITTI</a> Semantic Segmentation leaderboards upon publication.</p>
            </td>
          </tr>


        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Patents</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/surface_normal.png" width="180" height="140">
            </td>
            <td width="75%" valign="center">
              <p>
                <strong>Deterministic Calculation of 3D Normals for LiDAR Point Cloud</strong>
              </p>
              <strong>Enxu Li</strong>,
							Ryan Razani,
							Yuan Ren,
							Bingbing Liu
              <br>
              [patent submitted] 2021
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cps-net.jpg" alt="cs188" width="180" height="140">
            </td>
            <td width="75%" valign="center">
              <p>
                <strong>CPS-Net: Cluser-free Panoptic Segmentation Network for LiDAR Point Cloud</strong>
              </p>
              <strong>Enxu Li</strong>,
							Ryan Razani,
							Bingbing Liu
              <br>
              [patent submitted] 2021
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
