<!DOCTYPE HTML>
<html lang="en">

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Thomas EnXu Li</title>

  <meta name="robots" content="index,follow">
  <meta name="keywords" content="Thomas EnXu Li; 李恩旭; Enxu Li; Computer Vision; 3D Perception; Semantic Segmentation; Panoptic Segmentation; Deep Learning; Univeristy of Toronto; Engineering Science; U of T EngSci">
  <link rel="author" href="http://thomas-enxuli.github.io/">

  <meta name="author" content="Thomas EnXu Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="pooVJ9EtaFvhaK-2inOZ9-RwrHVBkyatI5mcS9mFK-U" />

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <script>
  // Some random colors
    const colors = ["#3CC157", "#2AA7FF", "#1B1B1B", "#FCBC0F", "#F85F36"];

    const numBalls = 50;
    const balls = [];

    for (let i = 0; i < numBalls; i++) {
      let ball = document.createElement("div");
      ball.classList.add("ball");
      ball.style.background = colors[Math.floor(Math.random() * colors.length)];
      let left_pos = Math.floor(Math.random() * 40);
      if (left_pos >= 20) {
        left_pos = left_pos + 60;
      }
      ball.style.left = `${left_pos}vw`;
      ball.style.top = `${Math.floor(Math.random() * 150)}vh`;
      ball.style.transform = `scale(${Math.random()})`;
      ball.style.width = `${Math.random()}em`;
      ball.style.height = ball.style.width;

      balls.push(ball);
      document.body.append(ball);
    }

    // Keyframes
    balls.forEach((el, i, ra) => {
      let to = {
        x: Math.random() * (i % 2 === 0 ? -11 : 11),
        y: Math.random() * 12
      };

      let anim = el.animate(
        [
          { transform: "translate(0, 0)" },
          { transform: `translate(${to.x}rem, ${to.y}rem)` }
        ],
        {
          duration: (Math.random() + 1) * 2000, // random duration
          direction: "alternate",
          fill: "both",
          iterations: Infinity,
          easing: "ease-in-out"
        }
      );
    });
</script>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color:#f9f9f9;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Thomas EnXu Li</name>
              </p>

              <p>I am a fourth year <a href="https://engsci.utoronto.ca/program/what-is-engsci/">Engineering Science</a> student at the University of Toronto, majoring in <strong>Robotics Engineering</strong> and minoring in <strong>Artificial Intelligence</strong> and <strong>Business</strong> . I'm in the process of completing my Professional Experience Year (PEY) as a <strong>research intern</strong> at <a href="http://www.noahlab.com.hk/#/home">Huawei Noah's Ark Research Lab</a>, where I work on <strong>LiDAR semantic segmentation and panoptic segmentation systems for self-driving vehicles</strong>. This September, I will be joining <a href="https://www.trailab.utias.utoronto.ca">The Toronto Robotics and AI Laboratory (TRAIL)</a> to work on my undergrad thesis with the guidance of <a href="https://www.trailab.utias.utoronto.ca/stevenwaslander">Prof. Steven Waslander</a>.
              </p>
              <p>
                What I value the most is creativity and productivity.
              </p>
              <p style="text-align:center">
                <a href="mailto:thomasenxu.li@mail.utoronto.ca">Email</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp -->
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.ca/citations?user=Bk4LuGYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/thomas-enxuli/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/thomas-enxu-li/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/thomas.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/thomas.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


<!-- education -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color: #f9f9f9;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/uoft.png" alt="clean-usnob" width="140" height="140">
            </td>
            <td width="75%" valign="middle">
              <papertitle>B.A.Sc in Engineering Science, Robotics (in progress)</papertitle>
              <br>
                Faculty of Applied Science and Engineering, University of Toronto
              <br>
                Sep 2017 - Apr 2022 | Toronto, ON
              <p> </p>
              <em><strong>3rd Year Annual GPA: 3.97</strong></em>
              <br>
              <em><strong>Daisy Intelligence Scholarship</strong>, 2020</em>
              <br>
              <em><strong>NSERC Undergraduate Research Award</strong>, 2019</em>
              <br>
              <em><strong>U of T Scholar</strong>, 2017</em>
              <br>
              <em><strong>Dean's Honour List - 2017-2021</strong></em>
            </td>
          </tr>
        </tbody></table>


<!-- research, publications -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, and robotics. Much of my research is about 3D perception with LiDAR point clouds.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <!-- <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/SMAC_nusc.gif" alt="cs188" width="180" height="140">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>SMAC-Seg: LiDAR Panoptic Segmentation via Sparse Multi-directional Attention Clustering</papertitle>
              <br>
              <strong>Enxu Li</strong>,
              <a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>,
              <a href="https://www.linkedin.com/in/richardxuyixuan/">Richard Xu</a>,
              <a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              [paper in preparation]
              <br>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CPS_kitti.gif" alt="cs188" width="180" height="140">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>CPSeg: A Real-time Cluster-free Panoptic Segmentation Network for LiDAR Point Clouds</papertitle>
                <br>
                <strong>Enxu Li</strong>,
                <a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>,
                <a href="https://www.linkedin.com/in/richardxuyixuan/">Richard Xu</a>,
                <a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
                <br>
                [paper in preparation]
              <br>
            </td>
          </tr> -->



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/gps3.gif" alt="clean-usnob" height="140" width="180">
              <!-- <img src="images/gps3.gif" alt="clean-usnob" width="180" height="140"> -->
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>GP-S3Net: Graph-based Panoptic Sparse Semantic Segmentation Network</papertitle>
              <br>
              <a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>*,
							<a href="https://rancheng.github.io/about/">Ran Cheng</a>*,
              <strong>Enxu Li</strong>,
							<a href="https://www.linkedin.com/in/taghav/">Ehsan Taghavi</a>,
              Yuan Ren,
							<a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              to appear at <a href="http://iccv2021.thecvf.com"><em>IEEE International Conference on Computer Vision (ICCV)</em></a>, 2021
              <br>
              <a href="https://arxiv.org/abs/2108.08401">arXiv</a>
              <br>
              <p>We present a novel panoptic segmentation network using <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_AF2-S3Net_Attentive_Feature_Fusion_With_Adaptive_Feature_Selection_for_Sparse_CVPR_2021_paper.pdf">(AF)2-S3Net</a> as the semantic backbone and a GCNN to segment foreground points into instances. This approach outperforms the current state-of-the-art approaches, by a significant margin across public available datasets such as, nuScenes and SemanticPOSS, ranking 1st on the competitive public <a href="https://competitions.codalab.org/competitions/24025#results">SemanticKITTI</a> leaderboard competition upon publication.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img src="images/af2s3.gif" alt="clean-usnob" width="180" height="140"> -->
              <img src="images/af2s3.gif" alt="clean-usnob" height="140" width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>(AF)2-S3Net: Attentive Feature Fusion with Adaptive Feature Selection for Sparse Semantic Segmentation Network</papertitle>
              <br>
							<a href="https://rancheng.github.io/about/">Ran Cheng</a>,
              <a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>,
              <a href="https://www.linkedin.com/in/taghav/">Ehsan Taghavi</a>,
              <strong>Enxu Li</strong>,
              <a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              <a href="http://cvpr2021.thecvf.com"><em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em></a>,2021 | virtual
              <br>
              <a href="pdfs/AF2S3_CVPR.pdf">PDF</a>
              /
              <a href="https://arxiv.org/abs/2102.04530">arXiv</a>
              <br>
              <p>We present a novel multi- branch attentive feature fusion module in the encoder and a unique adaptive feature selection module with feature map re-weighting in the decoder. This method ranks 1st on both <a href="https://www.nuscenes.org/lidar-segmentation?externalData=all&mapData=all&modalities=Any">nuScenes-lidarseg</a> and <a href="https://competitions.codalab.org/competitions/20331#results">SemanticKITTI</a> Semantic Segmentation leaderboards upon publication.</p>
            </td>
          </tr>


        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Patents</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img src="images/cps-net.jpg" alt="cs188" width="180" height="140"> -->
              <img src="images/CPS.png" alt="clean-usnob" height="140" width="140">
            </td>
            <td width="75%" valign="center">
              <p>
                <strong>CPS-Net: Cluser-free Panoptic Segmentation Network for LiDAR Point Cloud</strong>
              </p>
              <strong>Enxu Li</strong>,
							<a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>,
							<a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              [patent filing] 2021
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img src="images/cps-net.jpg" alt="cs188" width="180" height="140"> -->
              <img src="images/SMAC.jpg" alt="clean-usnob" height="140" width="140">
            </td>
            <td width="75%" valign="center">
              <p>
                <strong>SMAC-Seg: LiDAR Panoptic Segmentation via Sparse Multi-directional Attention Clustering</strong>
              </p>
              <strong>Enxu Li</strong>,
							<a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>,
							<a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              [patent filing] 2021
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img src="images/surface_normal.png" width="180" height="140"> -->
              <img src="images/surface_normal.png" alt="clean-usnob" height="140" width="140">
            </td>
            <td width="75%" valign="center">
              <p>
                <strong>Deterministic Calculation of 3D Normals for LiDAR Point Cloud</strong>
              </p>
              <strong>Enxu Li</strong>,
							<a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>,
							Yuan Ren,
							<a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              [patent filing] 2021
            </td>
          </tr>

        </tbody></table>

      </td>
    </tr>
  </table>

  <div align="center" style="margin:auto;padding-top:10px">
      <div style="width:10%">
          <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=5lT7tGELesewTHQZGh_SQyVkIxpVHQLsAJT50NzzwS0"></script>
      </div>
  </div>




</body>

</html>
