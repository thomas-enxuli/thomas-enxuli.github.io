<!DOCTYPE HTML>
<html lang="en">

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Thomas EnXu Li</title>

  <meta name="robots" content="index,follow">
  <meta name="keywords" content="Thomas EnXu Li; 李恩旭; Enxu Li; Computer Vision; 3D Perception; Semantic Segmentation; Panoptic Segmentation; Deep Learning; University of Toronto; Engineering Science; U of T EngSci">
  <link rel="author" href="http://thomas-enxuli.github.io/">

  <meta name="author" content="Thomas EnXu Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="google-site-verification" content="pooVJ9EtaFvhaK-2inOZ9-RwrHVBkyatI5mcS9mFK-U" />

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <script>
  // Some random colors
    const colors = ["#3CC157", "#2AA7FF", "#1B1B1B", "#FCBC0F", "#F85F36"];

    const numBalls = 50;
    const balls = [];

    for (let i = 0; i < numBalls; i++) {
      let ball = document.createElement("div");
      ball.classList.add("ball");
      ball.style.background = colors[Math.floor(Math.random() * colors.length)];
      let left_pos = Math.floor(Math.random() * 40);
      if (left_pos >= 20) {
        left_pos = left_pos + 60;
      }
      ball.style.left = `${left_pos}vw`;
      ball.style.top = `${Math.floor(Math.random() * 150)}vh`;
      ball.style.transform = `scale(${Math.random()})`;
      ball.style.width = `${Math.random()}em`;
      ball.style.height = ball.style.width;

      balls.push(ball);
      document.body.append(ball);
    }

    // Keyframes
    balls.forEach((el, i, ra) => {
      let to = {
        x: Math.random() * (i % 2 === 0 ? -11 : 11),
        y: Math.random() * 12
      };

      let anim = el.animate(
        [
          { transform: "translate(0, 0)" },
          { transform: `translate(${to.x}rem, ${to.y}rem)` }
        ],
        {
          duration: (Math.random() + 1) * 2000, // random duration
          direction: "alternate",
          fill: "both",
          iterations: Infinity,
          easing: "ease-in-out"
        }
      );
    });
</script>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color:#f9f9f9;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Thomas EnXu Li</name>
              </p>

              <p>I will start my PhD studies in Computer Science at the <a href="https://www.sgs.utoronto.ca/programs/computer-science/">University of Toronto</a> this September, supervised by <a href="https://www.cs.toronto.edu/~urtasun/">Prof. Raquel Urtasun</a>. Meanwhile, I will be a research scientist at <a href="https://waabi.ai">Waabi</a>. I earned my B.A.Sc in <a href="https://engsci.utoronto.ca/program/what-is-engsci/">Engineering Science</a> from University of Toronto, majoring in <strong>Robotics Engineering</strong> and minoring in <strong>Artificial Intelligence</strong> . During the last year of my undergradudate studies, I was fortunate to work with <a href="https://www.trailab.utias.utoronto.ca/stevenwaslander">Prof. Steven Waslander</a> on <strong>4D panoptic LiDAR segmentation</strong> framework. In 2020, I had the opportunity to work as a full time <strong>research intern</strong> at <a href="http://www.noahlab.com.hk/#/home">Huawei Noah's Ark Research Lab</a> for my 16-month PEY, where I research and develop <strong>LiDAR semantic segmentation and panoptic segmentation systems for self-driving vehicles</strong>.
              </p>
              <p>
                What I value the most is creativity and productivity.
              </p>
              <p style="text-align:center">
                <a href="mailto:thomasenxu.li@mail.utoronto.ca">Email</a> &nbsp/&nbsp
                <a href="pdfs/CV.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.ca/citations?user=Bk4LuGYAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://github.com/thomas-enxuli/">Github</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/thomas-enxu-li/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/thomas.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/thomas.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>


<!-- education -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Education</heading>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color: #f9f9f9;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/uoft.png" alt="clean-usnob" width="140" height="140">
            </td>
            <td width="75%" valign="middle">
              <papertitle>Ph.D in Computer Science (Incoming)</papertitle>
              <br>
                Department of Computer Science, University of Toronto
              <br>
                (Next) Sep 2022 - 2027 | Toronto, ON
              <p> </p>
              <br>
              <p> </p>
              <br>
              <p> </p>


            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;background-color: #f9f9f9;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/uoft.png" alt="clean-usnob" width="140" height="140">
            </td>
            <td width="75%" valign="middle">
              <papertitle>B.A.Sc in Engineering Science, Robotics</papertitle>
              <br>
                Faculty of Applied Science and Engineering, University of Toronto
              <br>
                Sep 2017 - Apr 2022 | Toronto, ON
              <p> </p>
              <em><strong>Major GPA</strong>: 3.99/4.00, <strong>cGPA</strong>: 3.87/4.00</em>
              <br>
              <em><strong>Daisy Intelligence Scholarship</strong>, 2020</em>
              <br>
              <em><strong>NSERC Undergraduate Research Award</strong>, 2019</em>
              <br>
              <em><strong>U of T Scholar</strong>, 2017</em>
              <br>
              <em><strong>Dean's Honour List - 2017-2022</strong></em>
            </td>
          </tr>
        </tbody></table>


<!-- research, publications -->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, and robotics. Much of my research is about 3D perception with LiDAR point clouds.
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>



          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CPS_kitti.gif" alt="cs188" width="180" height="140">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>CPSeg: Cluster-free Panoptic Segmentation of 3D LiDAR Point Clouds</papertitle>
              <br>
              <strong>Enxu Li</strong>*,
              <a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>*,
              <a href="https://www.linkedin.com/in/richardxuyixuan/">Yixuan Xu</a>,
              <a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              [under review]
              <br>
              <a href="https://arxiv.org/abs/2111.01723">arXiv</a>
              <br>
              <p>
                We propose a novel real-time end-to-end panoptic segmentation system for LiDAR point clouds, called CPSeg. It comprises of a shared backbone, a dual decoder, a novel task-aware attention module, and a new cluster-free instance segmentation head. Extensive experiments show that CPSeg achieves SOTA results as compared with existing real-time approaches on <a href="https://competitions.codalab.org/competitions/24025#results">SemanticKITTI</a> and nuScenes panoptic segmentation datasets.
                </p>
              </p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/SMAC_nusc.gif" alt="cs188" width="180" height="140">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>SMAC-Seg: LiDAR Panoptic Segmentation via Sparse Multi-directional Attention Clustering</papertitle>
              <br>
              <strong>Enxu Li</strong>*,
              <a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>*,
              <a href="https://www.linkedin.com/in/richardxuyixuan/">Yixuan Xu</a>,
              <a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              to appear at <a href="https://www.icra2022.org">2022 IEEE International Conference on Robotics and Automation (ICRA)</a>
              <br>
              <a href="https://arxiv.org/abs/2108.13588">arXiv</a>
              <br>
              <p>We propose a novel real-time LiDAR-based panoptic system, called SMAC-Seg, with a learnable sparse multi-directional attention clustering to segment multi-scale foreground instances. Further, we introduce a centroid-aware repel loss to effectively supervise the network to differentiate each object cluster with its closest neighbour. Our experimental results show that SMAC-Seg achieves SOTA performance among all published real-time approaches on both <a href="https://competitions.codalab.org/competitions/24025#results">SemanticKITTI</a> and nuScenes panoptic segmentation datasets.
              </p>
            </td>
          </tr>






          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/gps3.gif" alt="clean-usnob" height="140" width="180">
              <!-- <img src="images/gps3.gif" alt="clean-usnob" width="180" height="140"> -->
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>GP-S3Net: Graph-based Panoptic Sparse Semantic Segmentation Network</papertitle>
              <br>
              <a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>*,
							<a href="https://rancheng.github.io/about/">Ran Cheng</a>*,
              <strong>Enxu Li</strong>,
							<a href="https://www.linkedin.com/in/taghav/">Ehsan Taghavi</a>,
              Yuan Ren,
							<a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              <a href="http://iccv2021.thecvf.com"><em>IEEE International Conference on Computer Vision (ICCV)</em></a>, 2021 | virtual
              <br>
              <a href="pdfs/GPS3_ICCV.pdf">PDF</a>
              /
              <a href="https://arxiv.org/abs/2108.08401">arXiv</a>
              <br>
              <p>We present a novel panoptic segmentation network using <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Cheng_AF2-S3Net_Attentive_Feature_Fusion_With_Adaptive_Feature_Selection_for_Sparse_CVPR_2021_paper.pdf">(AF)2-S3Net</a> as the semantic backbone and a GCNN to segment foreground points into instances. This approach outperforms the current state-of-the-art approaches, by a significant margin across public available datasets such as, nuScenes and SemanticPOSS, ranking 1st on the competitive public <a href="https://competitions.codalab.org/competitions/24025#results">SemanticKITTI</a> leaderboard competition upon publication.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img src="images/af2s3.gif" alt="clean-usnob" width="180" height="140"> -->
              <img src="images/af2s3.gif" alt="clean-usnob" height="140" width="180">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>(AF)2-S3Net: Attentive Feature Fusion with Adaptive Feature Selection for Sparse Semantic Segmentation Network</papertitle>
              <br>
							<a href="https://rancheng.github.io/about/">Ran Cheng</a>,
              <a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>,
              <a href="https://www.linkedin.com/in/taghav/">Ehsan Taghavi</a>,
              <strong>Enxu Li</strong>,
              <a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              <a href="http://cvpr2021.thecvf.com"><em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em></a>,2021 | virtual
              <br>
              <a href="pdfs/AF2S3_CVPR.pdf">PDF</a>
              /
              <a href="https://arxiv.org/abs/2102.04530">arXiv</a>
              <br>
              <p>We present a novel multi- branch attentive feature fusion module in the encoder and a unique adaptive feature selection module with feature map re-weighting in the decoder. This method ranks 1st on both <a href="https://www.nuscenes.org/lidar-segmentation?externalData=all&mapData=all&modalities=Any">nuScenes-lidarseg</a> and <a href="https://competitions.codalab.org/competitions/20331#results">SemanticKITTI</a> Semantic Segmentation leaderboards upon publication.</p>
            </td>
          </tr>


        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Patents</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CPS.png" alt="clean-usnob"  width="140">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>System and Method for Proposal-free and Cluster-free Panoptic Segmentation of Point Clouds</strong>
              </p>
              <strong>Enxu Li</strong>,
							<a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>,
							<a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              [patent filing] 2021
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img src="images/cps-net.jpg" alt="cs188" width="180" height="140"> -->
              <img src="images/SMAC.jpg" alt="clean-usnob" width="140">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>System and Method for Panoptic Segmentation of Point Clouds</strong>
              </p>
              <strong>Enxu Li</strong>,
							<a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>,
							<a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              [patent filing] 2021

            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/surface_normal.png" alt="clean-usnob" width="140">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Methods and Systems for Deterministic Calculation of Surface Normal Vectors for Sparse Point Clouds</strong>
              </p>
              <strong>Enxu Li</strong>,
							<a href="https://www.linkedin.com/in/rnri/">Ryan Razani</a>,
							Yuan Ren,
							<a href="https://www.linkedin.com/in/bingbing-liu-9185a412/">Bingbing Liu</a>
              <br>
              [patent filing] 2021
            </td>
          </tr>

        </tbody></table>


        <!-- Work Experience -->



                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
                  <tr>
                    <td>
                      <heading>Work Experience</heading>
                    </td>
                  </tr>
                </tbody></table>
                <table width="100%" align="center" border="0" cellpadding="20"><tbody>

                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <!-- <img src="images/cps-net.jpg" alt="cs188" width="180" height="140"> -->
                      <img src="images/huawei.png" alt="clean-usnob" width="140">
                    </td>
                    <td width="75%" valign="center">
                      <p>
                        <strong>Machine Learning Research Intern</strong>
                      </p>
                      Huawei Technologies, <a href="https://noahlab.com.hk/#/home">Noah's Ark Research Lab</a>
                      <br>
                        May 2020 - Aug 2021 | Toronto, ON
                      <br>
                      <p>Research and development for autonomus driving systems. Focused topics: 3D LiDAR point cloud pre-processing, depth completion, surface normal computation, 3D semantic segmentation, 3D panoptic segmentation.</p>

                  </tr>




    <!-- projects -->

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Projects</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img src="images/cps-net.jpg" alt="cs188" width="180" height="140"> -->
              <img src="images/buddify.png" alt="clean-usnob" width="140">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Buddify</strong>
              </p>
              University of Toronto, Feb 2021



              <br>
              <a href="https://devpost.com/software/buddify">Website</a>
              /
              <a href="https://github.com/rachelwuuu/Buddify_uoftHacks">Code</a>
              <br>
                Created a smart platform to match individuals based on their personality and commoninterests, powered by Reactjs and Nodejs, built with machine learning clustering algorithms            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img src="images/cps-net.jpg" alt="cs188" width="180" height="140"> -->
              <img src="images/gesture.png" alt="clean-usnob" width="140">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>Gesture Controlled Claw Machine</strong>
              </p>
              University of Toronto, Apr 2020
              <br>
              <a href="pdfs/gesture.pdf">Technical Report</a>

                <br>
              Designed a gesture-controlled claw machine utilizing a wearable device rather than traditional joystick control.
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img src="images/cps-net.jpg" alt="cs188" width="180" height="140"> -->
              <img src="images/fooddet.png" alt="clean-usnob" width="140">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>FoodDet: A Deep Learning Food Recognition Model</strong>
              </p>
              University of Toronto, Aug 2019
              <br>
              <a href="pdfs/Fooddet_report.pdf">Technical Report</a>
              /
              <a href="https://github.com/thomas-enxuli/Deep-Learning-Food-Detection-Model">Code</a>
              /
              <a href="https://www.youtube.com/watch?v=HQsw-GnxONQ">Presentation</a>


                <br>
                Designed and Trained a food detector based on a Faster R-CNN variant as backbone on collected and processed data
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <!-- <img src="images/cps-net.jpg" alt="cs188" width="180" height="140"> -->
              <img src="images/ballballu.jpg" alt="clean-usnob" width="140">
            </td>
            <td width="75%" valign="top">
              <p>
                <strong>BALL BALL U: An Autonmous Ball Dispensing Prototype</strong>
              </p>
              <strong>Engineering Design Competition 2nd Place</strong>, University of Toronto, Apr 2019

              <br>
              <a href="pdfs/ballballu.pdf">Technical Report</a>
              /
              <a href="https://www.youtube.com/watch?v=QoKk82QAwg8">Glance</a>
              /
              <a href="https://www.youtube.com/watch?v=aJ0jOfGQD-g">Competition</a>

                <br>
              Designed, fabricated and programmed a proof-of-concept robot prototype that autonomously detect and deploy objects to canisters.
            </td>
          </tr>



        </tbody></table>

      </td>
    </tr>
  </table>










  <div align="center" style="margin:auto;padding-top:10px">
      <div style="width:10%">
          <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=5lT7tGELesewTHQZGh_SQyVkIxpVHQLsAJT50NzzwS0"></script>
      </div>
  </div>




</body>

</html>
